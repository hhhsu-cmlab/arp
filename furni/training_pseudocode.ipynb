{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import furniture_bench\n",
    "\n",
    "import gym\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#from arp.aloha.lerobot.common.utils.nn import SinusoidalPositionEmbedding2d\n",
    "\n",
    "import sys\n",
    "from arp.furni.dataset import FurnitureOfflineDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import arp.aloha.arp as arp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"arp/furni/configs/test0.yaml\", \"r\") as f:\n",
    "    full_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "config = full_config[\"policy\"]\n",
    "arp_cfg = full_config[\"policy\"][\"arp_cfg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate arp policy. \n",
    "\n",
    "See https://github.com/mlzxy/arp/issues/9 for the meaning of tokentypes and how to do compute_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = arp.AutoRegressivePolicy(arp.ModelConfig(\n",
    "    n_embd=arp_cfg[\"n_embd\"],\n",
    "    embd_pdrop=arp_cfg[\"embd_pdrop\"],\n",
    "    max_seq_len=config[\"chunk_size\"],\n",
    "    max_chunk_size=config[\"chunk_size\"],\n",
    "    layers=[\n",
    "        arp.LayerType.make(**arp_cfg[\"layer_cfg\"], condition_on='visual-tokens')\n",
    "    ] * arp_cfg[\"num_layers\"],\n",
    "    tokens=[\n",
    "        arp.TokenType.make(\n",
    "            name='state_ee_position', is_continuous=True, dim=3, embedding='linear', predictor='gmm', \n",
    "            predictor_kwargs={'num_latents': config[\"num_latents\"]}\n",
    "        ),\n",
    "        arp.TokenType.make(\n",
    "            name='state_ee_quaternion', is_continuous=True, dim=4, embedding='linear', predictor='gmm', \n",
    "            predictor_kwargs={'num_latents': config[\"num_latents\"]}\n",
    "        ),\n",
    "        arp.TokenType.make(\n",
    "            name='state_ee_velocity', is_continuous=True, dim=3, embedding='linear', predictor='gmm', \n",
    "            predictor_kwargs={'num_latents': config[\"num_latents\"]}\n",
    "        ),\n",
    "        arp.TokenType.make(\n",
    "            name='state_ee_angular_velocity', is_continuous=True, dim=3, embedding='linear', predictor='gmm', \n",
    "            predictor_kwargs={'num_latents': config[\"num_latents\"]}\n",
    "        ),\n",
    "        arp.TokenType.make(\n",
    "            name='state_joint_positions', is_continuous=True, dim=7, embedding='linear', predictor='gmm', \n",
    "            predictor_kwargs={'num_latents': config[\"num_latents\"]}\n",
    "        ),\n",
    "        arp.TokenType.make(\n",
    "            name='state_joint_velocities', is_continuous=True, dim=7, embedding='linear', predictor='gmm', \n",
    "            predictor_kwargs={'num_latents': config[\"num_latents\"]}\n",
    "        ),\n",
    "        arp.TokenType.make(\n",
    "            name='state_joint_torques', is_continuous=True, dim=7, embedding='linear', predictor='gmm', \n",
    "            predictor_kwargs={'num_latents': config[\"num_latents\"]}\n",
    "        ),\n",
    "        arp.TokenType.make(\n",
    "            name='action_ee_delta_position', is_continuous=True, dim=3, embedding='linear', predictor='gmm', \n",
    "            predictor_kwargs={'num_latents': config[\"num_latents\"]}\n",
    "        ),\n",
    "        arp.TokenType.make(\n",
    "            name='action_ee_delta_quaternion', is_continuous=True, dim=4, embedding='linear', predictor='gmm', \n",
    "            predictor_kwargs={'num_latents': config[\"num_latents\"]}\n",
    "        ),\n",
    "        arp.TokenType.make(\n",
    "            name='action_gripper_range', is_continuous=True, dim=1, embedding='linear', predictor='gmm', \n",
    "            predictor_kwargs={'num_latents': config[\"num_latents\"]}\n",
    "        )\n",
    "    ]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a map from each token type's name to its id. This map is automatically generated for you once `policy` is instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state_ee_position': 0,\n",
       " 'state_ee_quaternion': 1,\n",
       " 'state_ee_velocity': 2,\n",
       " 'state_ee_angular_velocity': 3,\n",
       " 'state_joint_positions': 4,\n",
       " 'state_joint_velocities': 5,\n",
       " 'state_joint_torques': 6,\n",
       " 'action_ee_delta_position': 7,\n",
       " 'action_ee_delta_quaternion': 8,\n",
       " 'action_gripper_range': 9}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.token_name_2_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop pseudocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./furniture-bench/data/low_compressed/lamp\"\n",
    "dataset = FurnitureOfflineDataset(\n",
    "    data_dir=data_dir,\n",
    "    batch_size=16,\n",
    "    seq_len=3\n",
    ")\n",
    "\n",
    "dataloader, sampler = dataset.dataloader()\n",
    "\n",
    "for batch in tqdm(dataloader):\n",
    "    batch_tuple = tuple(v for k, v in batch.items())\n",
    "    tk_vals = arp.cat_uneven_blc_tensors(**batch_tuple)\n",
    "    tk_ids = torch.as_tensor(tk_ids).to(device)[None, :, None].repeat(batch_size, 1, 1)\n",
    "    tks = torch.cat([tk_vals, tk_ids], dim=-1) \n",
    "    chk_ids = torch.as_tensor(chk_ids, device=device)[None, :]\n",
    "\n",
    "    loss_dict = self.policy.compute_loss(tks, chk_ids, contexts={ 'visual-tokens': encoder_out, \n",
    "            'visual-featmap': visual_featmap, \n",
    "            'smooth-heatmap-right': heatmap_right.flatten(0, 1), \n",
    "            'smooth-heatmap-left': heatmap_left.flatten(0, 1) }, valid_tk_mask=~tk_is_pad_mask)\n",
    "    \n",
    "    loss = sum(v for k, v in loss_dict.items())\n",
    "    loss.backward()\n",
    "\n",
    "\n",
    "# for batch in tqdm(dataloader):\n",
    "#     if i == 0:\n",
    "#         print(batch)\n",
    "    #batch = {k:v.to(device) for k,v in batch.items()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "furni1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
